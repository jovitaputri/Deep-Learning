{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A. Membuat Model GAN"
      ],
      "metadata": {
        "id": "3YN608itqkM7"
      },
      "id": "3YN608itqkM7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah pertama yang saya lakukan adalah import beberapa library yang nantinya membantu saya untuk menjalankan pembuatan model GAN nantinya. Lanjutannya, saya melakukan load folder zip yang terdapat image didalamnya."
      ],
      "metadata": {
        "id": "Vu-dKMdbq439"
      },
      "id": "Vu-dKMdbq439"
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from scipy.linalg import sqrtm"
      ],
      "metadata": {
        "id": "KWqMrV3iAa6X"
      },
      "id": "KWqMrV3iAa6X",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/sample_data/A_23-20250627T052734Z-1-001.zip\"\n",
        "extract_path = \"/content/sample_data/images/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "image_size = (100, 100)\n",
        "add_noise = True\n",
        "\n",
        "def add_gaussian_noise(image_array, mean=0.0, std=15.0):\n",
        "    gaussian = np.random.normal(loc=mean, scale=std, size=image_array.shape)\n",
        "    noisy_img = image_array + gaussian\n",
        "    return np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
        "\n",
        "image_files = []\n",
        "for root, _, files in os.walk(extract_path):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith('.jpg'):\n",
        "            image_files.append(os.path.join(root, filename))\n",
        "\n",
        "print(f\"Total gambar asli ditemukan: {len(image_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwYy1toZl85q",
        "outputId": "e8fc85c3-dcb7-4d3e-cd78-a2e96a21265c"
      },
      "id": "LwYy1toZl85q",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total gambar asli ditemukan: 1074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini saya melakukan split data dengan lanjutan dari soal no 2 sebelumnya."
      ],
      "metadata": {
        "id": "yOuTRMZXrU9I"
      },
      "id": "yOuTRMZXrU9I"
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = [], []\n",
        "for file_path in image_files:\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img = img.convert('RGB')\n",
        "            img = img.resize(image_size)\n",
        "            img_arr = np.array(img)\n",
        "            images.append(img_arr)\n",
        "            labels.append(os.path.basename(file_path))\n",
        "\n",
        "            if add_noise:\n",
        "                noisy_version = add_gaussian_noise(img_arr)\n",
        "                images.append(noisy_version)\n",
        "                labels.append(os.path.basename(file_path) + \"_noise\")\n",
        "    except Exception as err:\n",
        "        print(f\"Gagal membaca file {file_path}: {err}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Jumlah total data (termasuk noise): {len(images)}\")\n",
        "print(f\"Data latih: {len(X_train)}, Validasi: {len(X_val)}, Uji: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUXFMI6piLB",
        "outputId": "7cd40c89-4b4e-4f99-aafa-691a1641c676"
      },
      "id": "KuUXFMI6piLB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah total data (termasuk noise): 2148\n",
            "Data latih: 1718, Validasi: 215, Uji: 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## i. Generator"
      ],
      "metadata": {
        "id": "t82yTdGOshwr"
      },
      "id": "t82yTdGOshwr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi `build_generator()` membuat model untuk menghasilkan gambar 100×100×3 dari noise berdimensi 100. Model ini terdiri dari tiga layer `Conv2DTranspose` dengan filter 64, 32, dan 3, kernel 3×3, stride 1, padding ‘valid’, dan aktivasi ReLU, kecuali layer terakhir menggunakan aktivasi tanh. Layer awal menggunakan `Dense` untuk memperluas dimensi noise, kemudian diubah bentuknya dengan `Reshape`. Arsitektur ini sesuai ketentuan soal untuk membangun generator dengan output gambar RGB."
      ],
      "metadata": {
        "id": "reog_Co1sfGm"
      },
      "id": "reog_Co1sfGm"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b1a4210a",
      "metadata": {
        "id": "b1a4210a"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    noise_input = layers.Input(shape=(100,))\n",
        "\n",
        "    x = layers.Dense(25 * 25 * 64, activation='relu')(noise_input)\n",
        "    x = layers.Reshape((25, 25, 64))(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)  # 50x50\n",
        "\n",
        "    x = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    output = layers.Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(x)\n",
        "\n",
        "    model = models.Model(inputs=noise_input, outputs=output, name=\"Generator\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2214e702",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2214e702",
        "outputId": "cf0a7115-b9a4-4df1-81d9-0d0c03ff2ac1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)          │     \u001b[38;5;34m4,040,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m9,232\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │         \u001b[38;5;34m1,731\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,040,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,232</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,731</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,074,099\u001b[0m (15.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,074,099</span> (15.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,074,099\u001b[0m (15.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,074,099</span> (15.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "generator = build_generator()\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d009f9",
      "metadata": {
        "id": "99d009f9"
      },
      "source": [
        "## ii. Diskriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi `build_discriminator()` membuat model untuk mengklasifikasikan gambar 100×100×3 sebagai asli atau palsu. Model terdiri dari tiga layer Conv2D dengan filter 16, 32, dan 64, kernel 3×3, stride 1, padding ‘valid’, dan aktivasi ReLU. Setelah itu, output diratakan dengan `Flatten()` dan diteruskan ke layer dense tunggal dengan aktivasi sigmoid untuk menghasilkan probabilitas keaslian gambar, sesuai arsitektur yang diminta soal."
      ],
      "metadata": {
        "id": "PLKUGLakswP8"
      },
      "id": "PLKUGLakswP8"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b1c72198",
      "metadata": {
        "id": "b1c72198"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    image_input = layers.Input(shape=(100, 100, 3))\n",
        "\n",
        "    x = layers.Conv2D(16, kernel_size=3, strides=1, padding='valid', activation='relu')(image_input)\n",
        "    x = layers.Conv2D(32, kernel_size=3, strides=1, padding='valid', activation='relu')(x)\n",
        "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='valid', activation='relu')(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs=image_input, outputs=output, name=\"Discriminator\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "yc1rQUs-cTsV",
        "outputId": "7867fbb4-042a-4b07-e12f-76cec3f0d079"
      },
      "id": "yc1rQUs-cTsV",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Discriminator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Discriminator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m565504\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m565,505\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">565504</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">565,505</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m589,089\u001b[0m (2.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">589,089</span> (2.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m589,089\u001b[0m (2.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">589,089</span> (2.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "850b6c57",
      "metadata": {
        "id": "850b6c57"
      },
      "source": [
        "## iii. Optimizer Adam & Loss Binary Crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap ini mengatur pelatihan GAN dengan optimizer Adam (lr=0.0002, beta\\_1=0.5) yang umum digunakan agar stabil. Discriminator dikompilasi dan dibekukan agar saat melatih GAN, hanya generator yang belajar. Model `gan_model` menghubungkan noise ke output validitas dari discriminator, lalu dikompilasi dengan loss `binary_crossentropy` untuk melatih generator menghasilkan gambar yang meyakinkan."
      ],
      "metadata": {
        "id": "mo7i-eKYtQ1x"
      },
      "id": "mo7i-eKYtQ1x"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55b9da09",
      "metadata": {
        "id": "55b9da09"
      },
      "outputs": [],
      "source": [
        "gan_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator.compile(optimizer=gan_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "\n",
        "latent_input = layers.Input(shape=(100,))\n",
        "generated_image = generator(latent_input)\n",
        "validity_output = discriminator(generated_image)\n",
        "\n",
        "gan_model = Model(inputs=latent_input, outputs=validity_output, name=\"GAN\")\n",
        "gan_model.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9c4956",
      "metadata": {
        "id": "7d9c4956"
      },
      "source": [
        "# B. Modifikasi Model Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikutnya saya melakukan modifikasi pada model baseline dengan bertujuan :\n",
        "\n",
        "Generator_Modified dibuat untuk menghasilkan gambar sintetis dari vektor noise berdimensi 100. Arsitekturnya terdiri dari dense layer yang direshape menjadi fitur map 25×25×128, lalu diperbesar secara bertahap menjadi 100×100×3 melalui Conv2DTranspose. BatchNormalization disisipkan untuk menstabilkan pelatihan. Output-nya berupa gambar RGB dengan aktivasi tanh.\n",
        "\n",
        "Discriminator_Modified bertugas membedakan gambar asli dan palsu. Input berupa gambar 100×100×3 diproses melalui tiga Conv2D layer dengan Dropout untuk mengurangi overfitting. Setelah itu diflatten dan diklasifikasikan oleh satu Dense unit beraktivasi sigmoid, menghasilkan probabilitas keaslian gambar."
      ],
      "metadata": {
        "id": "1LNXdePZuov1"
      },
      "id": "1LNXdePZuov1"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e50d1a50",
      "metadata": {
        "id": "e50d1a50"
      },
      "outputs": [],
      "source": [
        "def build_generator_mod():\n",
        "    latent_vector = layers.Input(shape=(100,))\n",
        "\n",
        "    y = layers.Dense(25 * 25 * 128, activation='relu')(latent_vector)\n",
        "    y = layers.Reshape((25, 25, 128))(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "\n",
        "    y = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu')(y)\n",
        "    y = layers.BatchNormalization()(y)\n",
        "    y = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu')(y)\n",
        "    y = layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='tanh')(y)\n",
        "\n",
        "    generator_mod = models.Model(latent_vector, y, name=\"Generator_Modified\")\n",
        "    return generator_mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6ad530cd",
      "metadata": {
        "id": "6ad530cd"
      },
      "outputs": [],
      "source": [
        "def build_discriminator_mod():\n",
        "    input_img = layers.Input(shape=(100, 100, 3))\n",
        "\n",
        "    z = layers.Conv2D(32, kernel_size=3, strides=1, padding='valid', activation='relu')(input_img)\n",
        "    z = layers.Dropout(0.25)(z)\n",
        "    z = layers.Conv2D(64, kernel_size=3, strides=1, padding='valid', activation='relu')(z)\n",
        "    z = layers.Dropout(0.25)(z)\n",
        "    z = layers.Conv2D(128, kernel_size=3, strides=1, padding='valid', activation='relu')(z)\n",
        "\n",
        "    z = layers.Flatten()(z)\n",
        "    z = layers.Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "    discriminator_mod = models.Model(input_img, z, name=\"Discriminator_Modified\")\n",
        "    return discriminator_mod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "238cf52f",
      "metadata": {
        "id": "238cf52f"
      },
      "source": [
        "# C. Evaluasi Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap ini saya mengevaluasi kualitas gambar yang dihasilkan oleh model generator GAN dengan menghitung nilai Fréchet Inception Distance (FID). Pertama, fungsi calculate_fid() digunakan untuk menghitung jarak statistik antara distribusi fitur gambar nyata dan gambar hasil generator menggunakan model InceptionV3, setelah gambar di-resize ke ukuran 299×299 dan dipreproses. Selanjutnya, 100 sampel noise acak dibuat dan dimasukkan ke generator baseline untuk menghasilkan gambar sintetis, kemudian dibandingkan dengan gambar asli dari X_train untuk mendapatkan nilai FID baseline. Setelah itu, proses yang sama dilakukan menggunakan generator modifikasi untuk menghasilkan gambar dan menghitung FID modifikasi. Kedua nilai FID ini digunakan untuk menilai sejauh mana gambar hasil model mendekati kualitas distribusi gambar asli."
      ],
      "metadata": {
        "id": "QZyViXhXxaDc"
      },
      "id": "QZyViXhXxaDc"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "62c949f2",
      "metadata": {
        "id": "62c949f2"
      },
      "outputs": [],
      "source": [
        "def calculate_fid(real_imgs, gen_imgs):\n",
        "    inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "\n",
        "    real_resized = tf.image.resize(real_imgs, (299, 299)).numpy()\n",
        "    gen_resized = tf.image.resize(gen_imgs, (299, 299)).numpy()\n",
        "\n",
        "    real_preprocessed = preprocess_input(real_resized)\n",
        "    gen_preprocessed = preprocess_input(gen_resized)\n",
        "\n",
        "    real_features = inception_model.predict(real_preprocessed)\n",
        "    gen_features = inception_model.predict(gen_preprocessed)\n",
        "\n",
        "    mu_real, sigma_real = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu_gen, sigma_gen = gen_features.mean(axis=0), np.cov(gen_features, rowvar=False)\n",
        "\n",
        "    diff = np.sum((mu_real - mu_gen) ** 2)\n",
        "    cov_sqrt = sqrtm(sigma_real @ sigma_gen)\n",
        "\n",
        "    if np.iscomplexobj(cov_sqrt):\n",
        "        cov_sqrt = cov_sqrt.real\n",
        "\n",
        "    fid_value = diff + np.trace(sigma_real + sigma_gen - 2.0 * cov_sqrt)\n",
        "    return fid_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4a79bdbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a79bdbb",
        "outputId": "7e6f1d29-0fa9-468a-9a61-c09cb27a1f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11s/step\n",
            "FID Score Baseline: 11.10\n"
          ]
        }
      ],
      "source": [
        "sample_count = 100\n",
        "random_noise = tf.random.normal([sample_count, 100])\n",
        "gen_images = generator(random_noise, training=False)\n",
        "\n",
        "real_imgs = X_train[:sample_count].astype('float32') / 255.0\n",
        "real_resized = tf.image.resize(real_imgs, (299, 299))\n",
        "gen_resized = tf.image.resize(gen_images, (299, 299))\n",
        "\n",
        "fid_baseline = calculate_fid(real_resized, gen_resized)\n",
        "print(f\"FID Score Baseline: {fid_baseline:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e103ad9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e103ad9d",
        "outputId": "d52d684c-edfa-468f-f326-b81f14b911ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7s/step\n",
            "FID Score Modifikasi: 11.51\n"
          ]
        }
      ],
      "source": [
        "generator_mod = build_generator_mod()\n",
        "\n",
        "n_samples = 100\n",
        "noise_mod = tf.random.normal([n_samples, 100])\n",
        "generated_images_mod = generator_mod(noise_mod, training=False)\n",
        "\n",
        "real_images = X_train[:n_samples].astype('float32') / 255.0\n",
        "real_resized = tf.image.resize(real_images, (299, 299))\n",
        "generated_resized = tf.image.resize(generated_images_mod, (299, 299))\n",
        "\n",
        "fid_score_mod = calculate_fid(real_resized, generated_resized)\n",
        "print(f\"FID Score Modifikasi: {fid_score_mod:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil evaluasi menunjukkan bahwa skor FID untuk model baseline adalah 11.10, sedangkan model modifikasi mendapatkan skor 11.51. Selisihnya sangat sedikit yang berarti kualitas gambar yang dihasilkan oleh kedua model hampir sama namun model baseline lebih unggul. Oleh karena perbedaan yang tidak signifikan ini, maka model modifikasi masih dapat dianggap berhasil menghasilkan gambar sintetis yang cukup menyerupai data asli. Dengan kata lain, modifikasi yang dilakukan tidak memberikan peningkatan berarti, tetapi juga tidak menurunkan performa secara drastis."
      ],
      "metadata": {
        "id": "q1htqKjbyFjZ"
      },
      "id": "q1htqKjbyFjZ"
    },
    {
      "cell_type": "markdown",
      "id": "c5d2e33b",
      "metadata": {
        "id": "c5d2e33b"
      },
      "source": [
        "# D. Video Penjelasan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video terdapat pada link berikut:\n",
        "\n",
        "https://drive.google.com/drive/folders/1i66HebEyFdobM4UYxXD7Z4uCOQKslo8L?usp=drive_link"
      ],
      "metadata": {
        "id": "k5LYdu1fUlc7"
      },
      "id": "k5LYdu1fUlc7"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}